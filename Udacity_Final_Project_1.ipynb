{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Udacity Final Project 1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/moaaztaha/ud120-final_project/blob/master/Udacity_Final_Project_1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "0JkqhuVcNurM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('ud120-projects/final_project')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1wxL1n9NzIn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "44b582ee-7aee-4bd3-86ae-72a2db3a1763"
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import sys\n",
        "import pickle\n",
        "sys.path.append(\"../tools/\")\n",
        "\n",
        "from feature_format import featureFormat, targetFeatureSplit\n",
        "from tester import dump_classifier_and_data\n",
        "\n",
        "### Task 1: Select what features you'll use.\n",
        "### features_list is a list of strings, each of which is a feature name.\n",
        "### The first feature must be \"poi\".\n",
        "features_list = ['poi','salary', 'bonus', 'total_stock_value', 'exercised_stock_options', 'frac_to_poi', 'frac_from_poi', 'total_poi_person'] # You will need to use more features\n",
        "\n",
        "### Load the dictionary containing the dataset\n",
        "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
        "    data_dict = pickle.load(data_file)\n",
        "\n",
        "### Task 2: Remove outliers\n",
        "data_dict.pop('TOTAL', 0)\n",
        "keys = list(data_dict.keys())\n",
        "features = list(data_dict[keys[0]].keys())\n",
        "\n",
        "# Replace NaN with 0\n",
        "for key in keys:\n",
        "    for feature in features:\n",
        "      if data_dict[key][feature] == \"NaN\":\n",
        "        data_dict[key][feature] = 0\n",
        "\n",
        "### Task 3: Create new feature(s)\n",
        "# total_poi_person = from_this_person_to_poi + from_poi_to_this_person (no improvement)\n",
        "for key in keys:\n",
        "  data_dict[key]['total_poi_person'] = data_dict[key]['from_this_person_to_poi'] + data_dict[key]['from_poi_to_this_person']\n",
        "\n",
        "\n",
        "  \n",
        "# frac_from_poi = from_poi / all comming messages and frac_to_poi = to_poi / all sent messages\n",
        "for key in keys:\n",
        "  if data_dict[key]['to_messages'] == 0:\n",
        "    data_dict[key]['frac_from_poi']  = 0\n",
        "  else:\n",
        "    data_dict[key]['frac_from_poi'] = float(data_dict[key]['from_poi_to_this_person']) / float(data_dict[key]['to_messages'])\n",
        "  \n",
        "  if data_dict[key]['from_messages'] == 0:\n",
        "    data_dict[key]['frac_to_poi'] = 0\n",
        "  else:\n",
        "    data_dict[key]['frac_to_poi'] = float(data_dict[key]['from_this_person_to_poi']) / float(data_dict[key]['from_messages'])\n",
        "\n",
        "      \n",
        "### Store to my_dataset for easy export below.\n",
        "my_dataset = data_dict\n",
        "\n",
        "### Extract features and labels from dataset for local testing\n",
        "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
        "labels, features = targetFeatureSplit(data)\n",
        "\n",
        "### Task 4: Try a varity of classifiers\n",
        "### Please name your classifier clf for easy export below.\n",
        "### Note that if you want to do PCA or other multi-stage operations,\n",
        "### you'll need to use Pipelines. For more info:\n",
        "### http://scikit-learn.org/stable/modules/pipeline.html\n",
        "\n",
        "# Provided to give you a starting point. Try a variety of classifiers.\n",
        "#from sklearn.naive_bayes import GaussianNB\n",
        "#clf = GaussianNB()\n",
        "\n",
        "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
        "### using our testing script. Check the tester.py script in the final project\n",
        "### folder for details on the evaluation method, especially the test_classifier\n",
        "### function. Because of the small size of the dataset, the script uses\n",
        "### stratified shuffle split cross validation. For more info: \n",
        "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
        "\n",
        "# Example starting point. Try investigating other evaluation techniques!\n",
        "from sklearn.cross_validation import train_test_split\n",
        "features_train, features_test, labels_train, labels_test = \\\n",
        "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()\n",
        "clf.fit(features_train, labels_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "pred = clf.predict(features_test)\n",
        "print accuracy_score(pred, labels_test)\n",
        "\n",
        "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
        "### check your results. You do not need to change anything below, but make sure\n",
        "### that the version of poi_id.py that you submit can be run on its own and\n",
        "### generates the necessary .pkl files for validating your results.\n",
        "dump_classifier_and_data(clf, my_dataset, features_list)\n",
        "\n",
        "\n",
        "'''\n",
        "from sklearn.svm import SVC\n",
        "svc_clf = SVC()\n",
        "svc_clf.fit(features_train, labels_train)\n",
        "pred_svc = svc_clf.predict(features_test)\n",
        "acc_svc = accuracy_score(pred_svc, labels_test)\n",
        "dump_classifier_and_data(svc_clf, my_dataset, features_list)\n",
        "print \"Score of SVC: \" + str(acc_svc)\n",
        "'''"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.svm import SVC\\nsvc_clf = SVC()\\nsvc_clf.fit(features_train, labels_train)\\npred_svc = svc_clf.predict(features_test)\\nacc_svc = accuracy_score(pred_svc, labels_test)\\ndump_classifier_and_data(svc_clf, my_dataset, features_list)\\nprint \"Score of SVC: \" + str(acc_svc)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "H3pOraV_OF8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7b263c50-06ad-4e0b-8a5c-e4125d4d19c5"
      },
      "cell_type": "code",
      "source": [
        "# Tester\n",
        "#!/usr/bin/pickle\n",
        "\n",
        "\"\"\" a basic script for importing student's POI identifier,\n",
        " \n",
        "    requires that the algorithm, dataset, and features list\n",
        "    be written to my_classifier.pkl, my_dataset.pkl, and\n",
        "    my_feature_list.pkl, respectively\n",
        "\n",
        "    that process should happen at the end of poi_id.py\n",
        "\"\"\"\n",
        "\n",
        "import pickle\n",
        "import sys\n",
        "from sklearn.cross_validation import StratifiedShuffleSplit\n",
        "sys.path.append(\"../tools/\")\n",
        "from feature_format import featureFormat, targetFeatureSplit\n",
        "\n",
        "PERF_FORMAT_STRING = \"\\\n",
        "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
        "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
        "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
        "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
        "\n",
        "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
        "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
        "    labels, features = targetFeatureSplit(data)\n",
        "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
        "    true_negatives = 0\n",
        "    false_negatives = 0\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    for train_idx, test_idx in cv: \n",
        "        features_train = []\n",
        "        features_test  = []\n",
        "        labels_train   = []\n",
        "        labels_test    = []\n",
        "        for ii in train_idx:\n",
        "            features_train.append( features[ii] )\n",
        "            labels_train.append( labels[ii] )\n",
        "        for jj in test_idx:\n",
        "            features_test.append( features[jj] )\n",
        "            labels_test.append( labels[jj] )\n",
        "        \n",
        "        ### fit the classifier using training set, and test on test set\n",
        "        clf.fit(features_train, labels_train)\n",
        "        predictions = clf.predict(features_test)\n",
        "        for prediction, truth in zip(predictions, labels_test):\n",
        "            if prediction == 0 and truth == 0:\n",
        "                true_negatives += 1\n",
        "            elif prediction == 0 and truth == 1:\n",
        "                false_negatives += 1\n",
        "            elif prediction == 1 and truth == 0:\n",
        "                false_positives += 1\n",
        "            elif prediction == 1 and truth == 1:\n",
        "                true_positives += 1\n",
        "            else:\n",
        "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
        "                print \"All predictions should take value 0 or 1.\"\n",
        "                print \"Evaluating performance for processed predictions:\"\n",
        "                break\n",
        "    try:\n",
        "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
        "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
        "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
        "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
        "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
        "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
        "        print clf\n",
        "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
        "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
        "        print \"\"\n",
        "    except:\n",
        "        print \"Got a divide by zero when trying out:\", clf\n",
        "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n",
        "\n",
        "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
        "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
        "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
        "\n",
        "def dump_classifier_and_data(clf, dataset, feature_list):\n",
        "    with open(CLF_PICKLE_FILENAME, \"w\") as clf_outfile:\n",
        "        pickle.dump(clf, clf_outfile)\n",
        "    with open(DATASET_PICKLE_FILENAME, \"w\") as dataset_outfile:\n",
        "        pickle.dump(dataset, dataset_outfile)\n",
        "    with open(FEATURE_LIST_FILENAME, \"w\") as featurelist_outfile:\n",
        "        pickle.dump(feature_list, featurelist_outfile)\n",
        "\n",
        "def load_classifier_and_data():\n",
        "    with open(CLF_PICKLE_FILENAME, \"r\") as clf_infile:\n",
        "        clf = pickle.load(clf_infile)\n",
        "    with open(DATASET_PICKLE_FILENAME, \"r\") as dataset_infile:\n",
        "        dataset = pickle.load(dataset_infile)\n",
        "    with open(FEATURE_LIST_FILENAME, \"r\") as featurelist_infile:\n",
        "        feature_list = pickle.load(featurelist_infile)\n",
        "    return clf, dataset, feature_list\n",
        "\n",
        "def main():\n",
        "    ### load up student's classifier, dataset, and feature_list\n",
        "    clf, dataset, feature_list = load_classifier_and_data()\n",
        "    ### Run testing script\n",
        "    test_classifier(clf, dataset, feature_list)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB(priors=None)\n",
            "\tAccuracy: 0.85721\tPrecision: 0.50038\tRecall: 0.32750\tF1: 0.39589\tF2: 0.35181\n",
            "\tTotal predictions: 14000\tTrue positives:  655\tFalse positives:  654\tFalse negatives: 1345\tTrue negatives: 11346\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NQx0EmRKOhKo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}